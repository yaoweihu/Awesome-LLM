# Awesome-LLM
Summary of LLM Resources.

## Content

- [1. Survey](#1-survey)
- [2. Model](#2-model)
- [3. Pre-training](#3-pre-training)
- [3. Finetune](#4-finetune)
- [5. Inference](#5-inference)
- [6. Miscellaneous](#6-miscellaneous)
  
## 1. Survey
- [Large Language Models: A Survey](https://arxiv.org/abs/2402.06196)  
  2024.02 - Shervin Minaee - Snap Inc., USA  
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)  
  2023.03 - Wayne Xin Zhao - Renmin Runiversity, China

## 2. Model
### DeepSeek Series
- [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434)    
  2024.05 - Aixin Liu - DeepSeek-AI, China  
- [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954)  
  2024.01 - Xiao Bi - DeepSeek-AI, China
### LLaMA Series
- [The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)
  2024.07 - Meta Inc.

## 3. Pre-training
- [Teaching Transformers Causal Reasoning through Axiomatic Training](https://arxiv.org/abs/2407.07612)  
  2024.07 - Aniket Vashishtha - Microsoft Research, India  

## 4. Finetune
- [Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey](https://arxiv.org/abs/2403.14608)  
  2024.07 - Zeyu Han - Northeastern University, USA

## 5. Inference
- [A Survey on Efficient Inference for Large Language Models](https://arxiv.org/abs/2404.14294)
  2024.04 - Zixuan Zhou - Tsinghua University, China  

## 6. Miscellaneous
- [LiL'Log](https://lilianweng.github.io/archives/)  
